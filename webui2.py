#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import gradio as gr
from pathlib import Path
import pandas as pd
# ---------- å·¥å…· ----------
from pathlib import Path
from mini_editor import build_mini_editor
from train_webui import build_train_tab
from onnx_webui import build_onnx_tab
#å®æ—¶è¾“å‡º
# webui2.py é¡¶éƒ¨ï¼ˆå…¨å±€ï¼‰
import threading, queue, subprocess
from gradio import Timer

import threading, queue, subprocess

import subprocess
#æ‰§è¡Œå‘½ä»¤
def run_cmd(cmd: str, timeout: int = 60) -> str:
    """
    æ‰§è¡Œå‘½ä»¤å¹¶è¿”å›è¾“å‡º
    :param cmd: è¦æ‰§è¡Œçš„å‘½ä»¤
    :param timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    :return: å‘½ä»¤è¾“å‡ºæˆ–é”™è¯¯ä¿¡æ¯
    """
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)
        if result.returncode == 0:
            return result.stdout
        else:
            return f"   é”™è¯¯ï¼š{result.stderr}"
    except subprocess.TimeoutExpired:
        return f"   å‘½ä»¤è¶…æ—¶ï¼š{cmd}"
    except Exception as e:
        return f"   æ‰§è¡Œå¤±è´¥ï¼š{str(e)}"

#å…¨å±€è·¯å¾„æŸ¥æ‰¾
import subprocess
from pathlib import Path

def find_and_run_script(script_name: str, base_path: Path, args: str, timeout: int = 60, max_depth: int = 3) -> str:
    """
    é€’å½’åœ¨åŸºç¡€è·¯å¾„åŠå…¶å­ç›®å½•ä¸­æŸ¥æ‰¾è„šæœ¬å¹¶è¿è¡Œã€‚
    :param script_name: è„šæœ¬æ–‡ä»¶åï¼ˆå¦‚ "build_dataset.py"ï¼‰
    :param base_path: åŸºç¡€è·¯å¾„ï¼ˆPathå¯¹è±¡ï¼‰
    :param args: å‘½ä»¤è¡Œå‚æ•°ï¼ˆå¦‚ "--dir /path"ï¼‰
    :param timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    :param max_depth: æœ€å¤§æœç´¢æ·±åº¦ï¼ˆé»˜è®¤3çº§ï¼‰
    :return: æ‰§è¡Œæ—¥å¿—æˆ–é”™è¯¯ä¿¡æ¯
    """
    def search_script(directory: Path, current_depth: int) -> Path:
        """é€’å½’æœç´¢è„šæœ¬æ–‡ä»¶"""
        if current_depth > max_depth:
            return None
        # æ£€æŸ¥å½“å‰ç›®å½•
        script_path = directory / script_name
        if script_path.exists():
            return script_path
        # é€’å½’æœç´¢å­ç›®å½•
        for subdir in directory.iterdir():
            if subdir.is_dir():
                found = search_script(subdir, current_depth + 1)
                if found:
                    return found
        return None

    # å¼€å§‹æœç´¢
    found_path = search_script(base_path, 0)
    if found_path:
        script_dir = found_path.parent
        return run_cmd(f'cd "{script_dir}" && python {script_name} {args}', timeout)
    else:
        return f"   è„šæœ¬ä¸å­˜åœ¨ï¼š{script_name} åœ¨ {base_path} åŠå…¶å­ç›®å½•ä¸­ï¼ˆæœ€å¤§æ·±åº¦ {max_depth}ï¼‰"
def mds_script(script_name: str, args: str, timeout: int = 60) -> str:
    """
    è¿è¡Œ MakeDiffSinger ç›®å½•ä¸‹çš„è„šæœ¬ã€‚
    :param script_name: è„šæœ¬æ–‡ä»¶åï¼ˆå¦‚ "validate_lengths.py"ï¼‰
    :param args: å‘½ä»¤è¡Œå‚æ•°ï¼ˆå¦‚ "--dir /path"ï¼‰
    :param timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    :return: æ‰§è¡Œæ—¥å¿—æˆ–é”™è¯¯ä¿¡æ¯
    """
    script_path = MDS_BASE / script_name
    if not script_path.exists():
        return f"   è„šæœ¬ä¸å­˜åœ¨ï¼š{script_path}"
    cmd = f'cd "{MDS_BASE}" && python {script_name} {args}'
    return run_cmd(cmd, timeout)
class LiveRunner:
    """é€è¡Œå®æ—¶æ—¥å¿—å™¨ï¼ˆGradio 5.x ä¸“ç”¨ï¼‰"""
    def __init__(self):
        self.proc   = None
        self.q      = queue.Queue()
        self._hist  = []          # ç´¯è®¡å†å²

    def start(self, cmd: list, cwd: Path = Path(".")):
        if self.proc and self.proc.poll() is None:
            return                 # å·²æœ‰ä»»åŠ¡
        self._hist.clear()
        self.proc = subprocess.Popen(
            cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
            bufsize=1, universal_newlines=True
        )
        threading.Thread(target=self._reader, daemon=True).start()

    def _reader(self):
        for line in iter(self.proc.stdout.readline, ""):
            self.q.put(line)
        self.proc.wait()

    def stop(self):
        if self.proc and self.proc.poll() is None:
            self.proc.terminate()
            self.proc.wait()
        self.proc = None

    def read(self) -> str:
        """è¿”å›å†å² + æ–°è¡Œï¼ˆé€è¡Œç´¯è®¡ï¼‰"""
        new_lines = []
        while True:
            try:
                new_lines.append(self.q.get_nowait())
            except queue.Empty:
                break
        self._hist.extend(new_lines)
        return "".join(self._hist)


class LiveLog:
    def __init__(self):
        self.proc  = None
        self.q     = queue.Queue()
        self._lock = threading.Lock()
        self._hist = []          # â† æ–°å¢ï¼šå†å²ç¼“å­˜

    def start(self, cmd: list, cwd: Path = Path(".")):
        with self._lock:
            if self.proc and self.proc.poll() is None:
                return
        self._hist.clear()       # â† å¯åŠ¨æ—¶æ¸…ç©ºå†å²
        self.proc = subprocess.Popen(
            cmd, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
            bufsize=1, universal_newlines=True
        )
        threading.Thread(target=self._reader, daemon=True).start()

    def _reader(self):
        for line in iter(self.proc.stdout.readline, ""):
            self.q.put(line)
        self.proc.wait()

    def stop(self):
        with self._lock:
            if self.proc and self.proc.poll() is None:
                self.proc.terminate()
                self.proc.wait()
            self.proc = None

    def read(self) -> str:
        """è¿”å› å†å² + æ–°è¡Œï¼Œå®ç°é€è¡Œç´¯è®¡"""
        new_lines = []
        while True:
            try:
                new_lines.append(self.q.get_nowait())
            except queue.Empty:
                break
        self._hist.extend(new_lines)          # â† è¿½åŠ åˆ°å†å²
        return "".join(self._hist)            # â† è¿”å›ç´¯è®¡å…¨æ–‡
# å…¨å±€å®ä¾‹ï¼ˆæ‰€æœ‰æ¨¡å—å¯¼å…¥å³å¯ç”¨ï¼‰
live_log = LiveLog()

# è°ƒç”¨ä¸€æ¬¡å³å¯
live_runner = LiveRunner()   # å…¨å±€å®ä¾‹

def run_live(cmd: str, log: gr.Textbox):
    """å¯åŠ¨ä»»åŠ¡ + è¿”å›åˆå§‹æç¤º"""
    live_runner.stop()
    live_runner.start(cmd.split(), cwd=WORKSPACE)   # å¿…é¡»ç”¨ list å½¢å¼
    return " ä»»åŠ¡å·²å¯åŠ¨ï¼Œæ—¥å¿—å®æ—¶åˆ·æ–°ä¸­..."
# ============== è¡¥å……ï¼šconfig_tab å®Œæ•´å®ç° ==============
def build_acoustic_subtab(): 
    import yaml
    from pathlib import Path

    TEMPLATE_FILE = Path(__file__).resolve().parent / "DiffSinger" / "configs" / "templates" / "config_acoustic.yaml"
    EXPORT_DIR    = TEMPLATE_FILE.parent

    # ----------- å·¥å…·ï¼šè¯»/å†™ YAML -----------
    def load_template():
        if not TEMPLATE_FILE.exists():
            return None, f" æ¨¡æ¿ä¸å­˜åœ¨ï¼š{TEMPLATE_FILE}"
        with open(TEMPLATE_FILE, "r", encoding="utf-8") as f:
            cfg = yaml.safe_load(f)
        return cfg, f" å·²è½½å…¥æ¨¡æ¿ï¼š{TEMPLATE_FILE}"

    def export_new_config(
        model_name, datasets_df, lr, bs, max_step,
        pe, pe_ckpt, hnsep_ckpt, vocoder_ckpt,
        use_eng, use_bre, use_voi, use_ten,
        use_ks, use_sp, use_lang, use_spk,
        num_lang, num_spk,
        key_shift_range, vel_range,
        out_name,
    ):
        try:
            cfg = {
                "base_config": "configs/acoustic.yaml",
                "dictionaries": {"zh": "dictionaries/opencpop-extension.txt"},
                "extra_phonemes": [],
                "merged_phoneme_groups": [],
                "datasets": [],
                "binary_data_dir": f"data/{model_name}/binary",
                "binarization_args": {"num_workers": 0},
                "pe": pe,
                "pe_ckpt": pe_ckpt if pe == "rmvpe" else "",
                "hnsep": "vr",
                "hnsep_ckpt": hnsep_ckpt,
                "vocoder": "NsfHifiGAN",
                "vocoder_ckpt": vocoder_ckpt,
                "use_lang_id": use_lang,
                "num_lang": int(num_lang),
                "use_spk_id": use_spk,
                "num_spk": int(num_spk),
                "use_energy_embed": use_eng,
                "use_breathiness_embed": use_bre,
                "use_voicing_embed": use_voi,
                "use_tension_embed": use_ten,
                "use_key_shift_embed": use_ks,
                "use_speed_embed": use_sp,
                "augmentation_args": {
                    "random_pitch_shifting": {"enabled": True, "range": key_shift_range, "scale": 0.75},
                    "fixed_pitch_shifting": {"enabled": False, "targets": [-5., 5.], "scale": 0.5},
                    "random_time_stretching": {"enabled": True, "range": vel_range, "scale": 0.75},
                },
                "diffusion_type": "reflow",
                "enc_ffn_kernel_size": 3,
                "use_rope": True,
                "use_shallow_diffusion": True,
                "T_start": 0.4,
                "T_start_infer": 0.4,
                "K_step": 300,
                "K_step_infer": 300,
                "backbone_type": "lynxnet",
                "backbone_args": {
                    "num_channels": 1024,
                    "num_layers": 6,
                    "kernel_size": 31,
                    "dropout_rate": 0.0,
                    "strong_cond": True,
                },
                "shallow_diffusion_args": {
                    "train_aux_decoder": True,
                    "train_diffusion": True,
                    "val_gt_start": False,
                    "aux_decoder_arch": "convnext",
                    "aux_decoder_args": {
                        "num_channels": 512,
                        "num_layers": 6,
                        "kernel_size": 7,
                        "dropout_rate": 0.1,
                    },
                    "aux_decoder_grad": 0.1,
                },
                "lambda_aux_mel_loss": 0.2,
                "optimizer_args": {"lr": float(lr)},
                "lr_scheduler_args": {
                    "scheduler_cls": "torch.optim.lr_scheduler.StepLR",
                    "step_size": 10000,
                    "gamma": 0.75,
                },
                "max_batch_frames": 50000,
                "max_batch_size": int(bs),
                "max_updates": int(max_step),
                "num_valid_plots": 10,
                "val_with_vocoder": True,
                "val_check_interval": 2000,
                "num_ckpt_keep": 5,
                "permanent_ckpt_start": 120000,
                "permanent_ckpt_interval": 20000,
                "pl_trainer_devices": "auto",
                "pl_trainer_precision": "16-mixed",
            }

            for row in datasets_df.itertuples(index=False):
                cfg["datasets"].append({
                    "raw_data_dir": row.raw_data_dir,
                    "speaker": row.speaker,
                    "spk_id": int(row.spk_id),
                    "language": row.language,
                    "test_prefixes": [p.strip() for p in row.test_prefixes.split(",") if p.strip()],
                })

            out_file = EXPORT_DIR / f"new_{out_name}.yaml"
            with open(out_file, "w", encoding="utf-8") as f:
                yaml.dump(cfg, f, allow_unicode=True, sort_keys=False)
            return f"  å·²å¯¼å‡ºï¼š{out_file}"
        except Exception as e:
            return f"  å¯¼å‡ºå¤±è´¥ï¼š{str(e)}"

    # ---------------- ç•Œé¢ ----------------
    with gr.Blocks(title="å£°å­¦æ¨¡å‹é…ç½®") as blk:
        gr.Markdown("## ğŸ›ï¸ å£°å­¦æ¨¡å‹é…ç½®ç”Ÿæˆå™¨ï¼ˆè‡ªåŠ¨æ£€æµ‹æ¨¡æ¿ï¼‰")

        # é¡¶éƒ¨çŠ¶æ€
        with gr.Row():
            load_st = gr.Textbox(value="", label="æ¨¡æ¿çŠ¶æ€", interactive=False, scale=4)
            reload_btn = gr.Button("ğŸ”„ é‡æ–°æ£€æµ‹", scale=1)

        # å·¦ä¾§ï¼šåŸºç¡€ä¿¡æ¯
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("#### åŸºç¡€ä¿¡æ¯")
                model_name = gr.Textbox(value="my_acoustic", label="æ¨¡å‹åï¼ˆnew_xxx.yaml å‰ç¼€ï¼‰", placeholder="my_acoustic")
                base_cfg   = gr.Textbox(value=str(TEMPLATE_FILE), interactive=False, label="æ¨¡æ¿è·¯å¾„")
                bin_dir    = gr.Textbox(value="", interactive=False, label="é¢„å¤„ç†è¾“å‡ºç›®å½•")

            # å³ä¾§ï¼šå¯è°ƒå‚æ•°
            with gr.Column(scale=2):
                gr.Markdown("#### å¯è°ƒè®­ç»ƒå‚æ•°")
                with gr.Row():
                    lr = gr.Number(value=0.0006, label="åˆå§‹å­¦ä¹ ç‡")
                    bs = gr.Number(value=64, label="max_batch_size")
                    max_step = gr.Number(value=160000, label="max_updates")
                with gr.Row():
                    pe = gr.Radio(["parselmouth", "rmvpe"], value="parselmouth", label="éŸ³é«˜æå–å™¨")
                    pe_ckpt = gr.Textbox(value="checkpoints/rmvpe/model.pt", label="rmvpe æ¨¡å‹è·¯å¾„")
                with gr.Row():
                    hnsep_ckpt = gr.Textbox(value="checkpoints/vr/model.pt", label="vr æ¨¡å‹è·¯å¾„")
                    vocoder_ckpt = gr.Textbox(value="checkpoints/nsf_hifigan_44.1k_hop512_128bin_2024.02/model.ckpt", label="å£°ç å™¨ ckpt")
                with gr.Row():
                    use_eng = gr.Checkbox(value=False, label="use_energy_embed")
                    use_bre = gr.Checkbox(value=False, label="use_breathiness_embed")
                    use_voi = gr.Checkbox(value=False, label="use_voicing_embed")
                    use_ten = gr.Checkbox(value=False, label="use_tension_embed")
                with gr.Row():
                    use_ks = gr.Checkbox(value=True, label="use_key_shift_embed")
                    use_sp = gr.Checkbox(value=True, label="use_speed_embed")
                    use_lang = gr.Checkbox(value=False, label="å¤šè¯­è¨€")
                    use_spk  = gr.Checkbox(value=False, label="å¤šè¯´è¯äºº")
                with gr.Row():
                    num_lang = gr.Number(value=1, precision=0, label="è¯­è¨€æ€»æ•°")
                    num_spk  = gr.Number(value=1, precision=0, label="è¯´è¯äººæ€»æ•°")
                with gr.Row():
                    key_shift_range = gr.Slider([-12, 12], value=(-5, 5), step=0.5, label="éšæœºå˜è°ƒèŒƒå›´")
                    vel_range       = gr.Slider([0.1, 3], value=(0.5, 2), step=0.1, label="éšæœºå˜é€ŸèŒƒå›´")

        # æ•°æ®é›†åŠ¨æ€è¡¨æ ¼
        gr.Markdown("#### æ•°æ®é›†åˆ—è¡¨ï¼ˆåŠ¨æ€å¢å‡ï¼‰")
        with gr.Row():
            add_btn = gr.Button(" æ·»åŠ è¡Œ", scale=1)
            del_btn = gr.Button(" åˆ é™¤æœ«è¡Œ", scale=1)
        ds_df = gr.Dataframe(
    headers=["raw_data_dir", "speaker", "spk_id", "language", "test_prefixes"],
    datatype=["str", "str", "number", "str", "str"],
    value=[["data/xxx1/raw", "speaker1", 0, "zh", "wav1,wav2"]],
    row_count=(1, 20),    # æœ€å° 1 è¡Œï¼Œæœ€å¤§ 20 è¡Œ
    interactive=True,
)




        add_btn.click(
    lambda df: pd.concat([df, pd.DataFrame([["data/xxx/raw", "speaker", 0, "zh", "test"]], columns=df.columns)], ignore_index=True),
    inputs=ds_df,
    outputs=ds_df
)



        # å¯¼å‡º
        with gr.Row():
            out_name = gr.Textbox(value="my_acoustic", label="å¯¼å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆä¸å« .yamlï¼‰")
            export_btn = gr.Button("ğŸ“¥ å¯¼å‡º new_xxx.yaml", variant="primary")
            export_log = gr.Textbox(label="æ—¥å¿—", interactive=False)

        # äº‹ä»¶
        export_btn.click(
            export_new_config,
            inputs=[
                out_name, ds_df, lr, bs, max_step,
                pe, pe_ckpt, hnsep_ckpt, vocoder_ckpt,
                use_eng, use_bre, use_voi, use_ten,
                use_ks, use_sp, use_lang, use_spk,
                num_lang, num_spk,
                key_shift_range, vel_range,
                out_name,
            ],
            outputs=export_log,
        )

        # å¯åŠ¨æ—¶è‡ªåŠ¨æ£€æµ‹æ¨¡æ¿
        def on_load():
            cfg, msg = load_template()
            if cfg is None:
                return msg, "", ""
            return (
                msg,
                cfg.get("binary_data_dir", "").replace("/binary", "")[5:],  # å‰¥æ‰ data/xxx/binary â†’ xxx
                cfg.get("optimizer_args", {}).get("lr", 0.0006),
            )
        blk.load(on_load, outputs=[load_st, model_name, lr])

    return blk
# ============== END config_tab ===============

def build_variance_subtab():
    import yaml, gradio as gr
    from pathlib import Path

    TEMPLATE_FILE = Path(__file__).resolve().parent / "DiffSinger" / "configs" / "templates" / "config_variance.yaml"
    EXPORT_DIR    = TEMPLATE_FILE.parent

    # ---------------- å·¥å…· ----------------
    def load_var_template():
        if not TEMPLATE_FILE.exists():
            return None, f"  å”±æ³•æ¨¡æ¿ä¸å­˜åœ¨ï¼š{TEMPLATE_FILE}"
        with open(TEMPLATE_FILE, "r", encoding="utf-8") as f:
            cfg = yaml.safe_load(f)
        return cfg, f"  å·²è½½å…¥å”±æ³•æ¨¡æ¿ï¼š{TEMPLATE_FILE}"

    def export_variance_config(
        model_name, datasets_df,
        lr, bs, max_step,
        pe, pe_ckpt, hnsep_ckpt,
        pred_dur, pred_pitch, pred_eng, pred_bre, pred_voi, pred_ten,
        eng_min, eng_max, bre_min, bre_max, voi_min, voi_max, ten_min, ten_max,
        use_melody, melody_hidden,
        use_glide, glide_types, glide_scale,
        out_prefix,
        dictionaries_config,    # å­—å…¸é…ç½®{è¯­è¨€: è·¯å¾„}
        extra_phonemes_list,    # ç‰¹æ®ŠéŸ³ç´ åˆ—è¡¨
        merged_phonemes_groups, # åˆå¹¶éŸ³ç´ ç»„
        vocoder_type,          # å£°ç å™¨ç±»å‹
        vocoder_ckpt,          # å£°ç å™¨æ£€æŸ¥ç‚¹
        use_lang,              # ä½¿ç”¨å¤šè¯­è¨€
        num_lang,              # è¯­è¨€æ•°é‡
        use_spk,               # ä½¿ç”¨å¤šè¯´è¯äºº
        num_spk,               # è¯´è¯äººæ•°é‡
    ):
        try:
            cfg = {
                "base_config": "configs/variance.yaml",
                "dictionaries": {"zh": "dictionaries/opencpop-extension.txt"},
                "extra_phonemes": [],
                "merged_phoneme_groups": [],
                "datasets": [],
                "binary_data_dir": f"data/{model_name}/binary",
                "binarization_args": {"num_workers": 0},
                "pe": pe,
                "pe_ckpt": pe_ckpt if pe == "rmvpe" else "",
                "hnsep": "vr",
                "hnsep_ckpt": hnsep_ckpt,
                "use_lang_id": False,
                "num_lang": 1,
                "use_spk_id": False,
                "num_spk": 1,
                "predict_dur": pred_dur,
                "predict_pitch": pred_pitch,
                "predict_energy": pred_eng,
                "predict_breathiness": pred_bre,
                "predict_voicing": pred_voi,
                "predict_tension": pred_ten,
                "energy_db_min": eng_min,
                "energy_db_max": eng_max,
                "breathiness_db_min": bre_min,
                "breathiness_db_max": bre_max,
                "voicing_db_min": voi_min,
                "voicing_db_max": voi_max,
                "tension_logit_min": ten_min,
                "tension_logit_max": ten_max,
                "enc_ffn_kernel_size": 3,
                "use_rope": True,
                "hidden_size": 256,
                "dur_prediction_args": {
                    "arch": "fs2",
                    "hidden_size": 512,
                    "dropout": 0.1,
                    "num_layers": 5,
                    "kernel_size": 3,
                    "log_offset": 1.0,
                    "loss_type": "mse",
                    "lambda_pdur_loss": 0.3,
                    "lambda_wdur_loss": 1.0,
                    "lambda_sdur_loss": 3.0,
                },
                "use_melody_encoder": use_melody,
                "melody_encoder_args": {
                    "hidden_size": melody_hidden,
                    "enc_layers": 4,
                },
                "use_glide_embed": use_glide,
                "glide_types": glide_types,
                "glide_embed_scale": glide_scale,
                "diffusion_type": "reflow",
                "pitch_prediction_args": {
                    "pitd_norm_min": -8.0,
                    "pitd_norm_max": 8.0,
                    "pitd_clip_min": -12.0,
                    "pitd_clip_max": 12.0,
                    "repeat_bins": 64,
                    "backbone_type": "wavenet",
                    "backbone_args": {
                        "num_layers": 20,
                        "num_channels": 256,
                        "dilation_cycle_length": 5,
                    },
                },
                "variances_prediction_args": {
                    "total_repeat_bins": 48,
                    "backbone_type": "wavenet",
                    "backbone_args": {
                        "num_layers": 10,
                        "num_channels": 192,
                        "dilation_cycle_length": 4,
                    },
                },
                "lambda_dur_loss": 1.0,
                "lambda_pitch_loss": 1.0,
                "lambda_var_loss": 1.0,
                "optimizer_args": {"lr": float(lr)},
                "lr_scheduler_args": {
                    "scheduler_cls": "torch.optim.lr_scheduler.StepLR",
                    "step_size": 10000,
                    "gamma": 0.75,
                },
                "max_batch_frames": 80000,
                "max_batch_size": int(bs),
                "max_updates": int(max_step),
                "num_valid_plots": 10,
                "val_check_interval": 2000,
                "num_ckpt_keep": 5,
                "permanent_ckpt_start": 80000,
                "permanent_ckpt_interval": 10000,
                "pl_trainer_devices": "auto",
                "pl_trainer_precision": "16-mixed",
                "dictionaries": dictionaries_config,
                "extra_phonemes": extra_phonemes_list,
                "merged_phoneme_groups": merged_phonemes_groups,
                "vocoder": vocoder_type,
                "vocoder_ckpt": vocoder_ckpt,
                "use_lang_id": use_lang,
                "num_lang": num_lang,
                "use_spk_id": use_spk,
                "num_spk": num_spk,
            }

            for row in datasets_df.itertuples(index=False):
                cfg["datasets"].append({
                    "raw_data_dir": row.raw_data_dir,
                    "speaker": row.speaker,
                    "spk_id": int(row.spk_id),
                    "language": row.language,
                    "test_prefixes": [p.strip() for p in row.test_prefixes.split(",") if p.strip()],
                })

            out_file = EXPORT_DIR / f"new_{out_prefix}_variance.yaml"
            with open(out_file, "w", encoding="utf-8") as f:
                yaml.dump(cfg, f, allow_unicode=True, sort_keys=False)
            return f"  å·²å¯¼å‡ºå”±æ³•é…ç½®ï¼š{out_file}"
        except Exception as e:
            return f"  å¯¼å‡ºå¤±è´¥ï¼š{str(e)}"

    # ---------------- ç•Œé¢ï¼šå”±æ³•é…ç½®å‰¯æ ‡ç­¾é¡µ ----------------
    with gr.Blocks() as blk:
        gr.Markdown("###  å”±æ³•æ¨¡å‹å‚æ•°ï¼ˆvarianceï¼‰")

        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("#### åŸºç¡€ä¿¡æ¯")
                model_name = gr.Textbox(value="my_var", label="æ¨¡å‹åï¼ˆnew_xxx_variance.yaml å‰ç¼€ï¼‰")
                load_st = gr.Textbox(value="", label="æ¨¡æ¿çŠ¶æ€", interactive=False)

            with gr.Column(scale=2):
                gr.Markdown("#### å¯è°ƒè®­ç»ƒå‚æ•°")
                lr = gr.Number(value=0.0006, label="åˆå§‹å­¦ä¹ ç‡")
                bs = gr.Number(value=48, label="max_batch_size")
                max_step = gr.Number(value=160000, label="max_updates")

        with gr.Row():
            pe = gr.Radio(["parselmouth", "rmvpe"], value="parselmouth", label="éŸ³é«˜æå–å™¨")
            pe_ckpt = gr.Textbox(value="checkpoints/rmvpe/model.pt", label="rmvpe æ¨¡å‹è·¯å¾„")
            hnsep_ckpt = gr.Textbox(value="checkpoints/vr/model.pt", label="vr æ¨¡å‹è·¯å¾„")

        gr.Markdown("#### é¢„æµ‹å¼€å…³ï¼ˆä¸å£°å­¦é…ç½®ä¿æŒä¸€è‡´ï¼‰")
        with gr.Row():
            pred_dur = gr.Checkbox(value=True, label="predict_durï¼ˆéŸ³ç´ é•¿åº¦ï¼‰")
            pred_pitch = gr.Checkbox(value=True, label="predict_pitchï¼ˆéŸ³é«˜ï¼‰")
            pred_eng = gr.Checkbox(value=False, label="predict_energy")
            pred_bre = gr.Checkbox(value=False, label="predict_breathiness")
            pred_voi = gr.Checkbox(value=False, label="predict_voicing")
            pred_ten = gr.Checkbox(value=False, label="predict_tension")

        gr.Markdown("#### å‚æ•°èŒƒå›´ï¼ˆä¸å»ºè®®éšæ„ä¿®æ”¹ï¼‰")
        with gr.Row():
            eng_min = gr.Number(value=-96.0, label="energy_db_min")
            eng_max = gr.Number(value=-12.0, label="energy_db_max")
            bre_min = gr.Number(value=-96.0, label="breathiness_db_min")
            bre_max = gr.Number(value=-20.0, label="breathiness_db_max")
            voi_min = gr.Number(value=-96.0, label="voicing_db_min")
            voi_max = gr.Number(value=-12.0, label="voicing_db_max")
            ten_min = gr.Number(value=-10.0, label="tension_logit_min")
            ten_max = gr.Number(value=10.0, label="tension_logit_max")

        gr.Markdown("#### é«˜çº§åŠŸèƒ½")
        with gr.Row():
            use_melody = gr.Checkbox(value=False, label="use_melody_encoderï¼ˆæ—‹å¾‹ç¼–ç å™¨ï¼‰")
            melody_hidden = gr.Number(value=128, label="melody_hidden_size")
            use_glide = gr.Checkbox(value=False, label="use_glide_embedï¼ˆæ»‘éŸ³ï¼Œéœ€æ ‡æ³¨ï¼‰")
            glide_types = gr.Textbox(value="up,down", label="glide_typesï¼ˆé€—å·åˆ†éš”ï¼‰")
            glide_scale = gr.Number(value=11.3137, label="glide_embed_scaleï¼ˆé»˜è®¤å³å¯ï¼‰")

        gr.Markdown("#### å­—å…¸ä¸å£°ç å™¨é…ç½®")
        with gr.Row():
           dictionaries_config = gr.JSON(value={"zh": "dictionaries/opencpop-extension.txt"}, label="å­—å…¸é…ç½®ï¼ˆJSONï¼‰")
           extra_phonemes_list = gr.Textbox(value="", label="é¢å¤–éŸ³ç´ ï¼ˆé€—å·åˆ†éš”ï¼‰")
           merged_phonemes_groups = gr.Textbox(value="", label="åˆå¹¶éŸ³ç´ ç»„ï¼ˆJSON åˆ—è¡¨ï¼‰")

        with gr.Row():
           vocoder_type = gr.Textbox(value="NsfHifiGAN", label="å£°ç å™¨ç±»å‹")
           vocoder_ckpt = gr.Textbox(value="checkpoints/nsf_hifigan_44.1k_hop512_128bin_2024.02/model.ckpt", label="å£°ç å™¨ ckpt")

        with gr.Row():
           use_lang = gr.Checkbox(value=False, label="ä½¿ç”¨å¤šè¯­è¨€")
           num_lang = gr.Number(value=1, precision=0, label="è¯­è¨€æ•°")
           use_spk = gr.Checkbox(value=False, label="ä½¿ç”¨å¤šè¯´è¯äºº")
           num_spk = gr.Number(value=1, precision=0, label="è¯´è¯äººæ•°")




        # æ•°æ®é›†è¡¨æ ¼ï¼ˆä¸å£°å­¦å…±ç”¨ç»“æ„ï¼‰
        gr.Markdown("#### æ•°æ®é›†åˆ—è¡¨ï¼ˆä¸å£°å­¦é…ç½®å…±ç”¨ç»“æ„ï¼‰")
        with gr.Row():
            add_btn = gr.Button(" æ·»åŠ è¡Œ", scale=1)
            del_btn = gr.Button(" åˆ é™¤æœ«è¡Œ", scale=1)
        ds_df = gr.Dataframe(
            headers=["raw_data_dir", "speaker", "spk_id", "language", "test_prefixes"],
            datatype=["str", "str", "number", "str", "str"],
            value=[["data/xxx1/raw", "speaker1", 0, "zh", "wav1,wav2"]],
            row_count=(1, 20),
            interactive=True,
        )

        add_btn.click(
    lambda df: pd.concat([df, pd.DataFrame([["data/xxx/raw", "speaker", 0, "zh", "test"]], columns=df.columns)], ignore_index=True),
    inputs=ds_df,
    outputs=ds_df
)
        # å¯¼å‡º
        with gr.Row():
            out_prefix = gr.Textbox(value="my_var", label="å¯¼å‡ºæ–‡ä»¶åå‰ç¼€ï¼ˆä¸å« .yamlï¼‰")
            export_btn = gr.Button(" å¯¼å‡º new_xxx_variance.yaml", variant="primary")
            export_log = gr.Textbox(label="æ—¥å¿—", interactive=False)

#äº‹ä»¶ç»‘å®š
    export_btn.click(
            export_variance_config,
            inputs=[
                out_prefix, ds_df, lr, bs, max_step,
                pe, pe_ckpt, hnsep_ckpt,
                pred_dur, pred_pitch, pred_eng, pred_bre, pred_voi, pred_ten,
                eng_min, eng_max, bre_min, bre_max, voi_min, voi_max, ten_min, ten_max,
                use_melody, melody_hidden,
                use_glide, glide_types, glide_scale,
                out_prefix,
            ],
            outputs=export_log,
        )
        
    export_btn.click(
    export_variance_config,
    inputs=[
        out_prefix, ds_df, lr, bs, max_step,
        pe, pe_ckpt, hnsep_ckpt,
        pred_dur, pred_pitch, pred_eng, pred_bre, pred_voi, pred_ten,
        eng_min, eng_max, bre_min, bre_max, voi_min, voi_max, ten_min, ten_max,
        use_melody, melody_hidden,
        use_glide, glide_types, glide_scale,
        out_prefix,
        dictionaries_config,
        extra_phonemes_list,
        merged_phonemes_groups,
        vocoder_type,
        vocoder_ckpt,
        use_lang,
        num_lang,
        use_spk,
        num_spk,
    ],
    outputs=export_log,
)


        # å¯åŠ¨æ—¶æ£€æµ‹æ¨¡æ¿
    def on_load():
            cfg, msg = load_var_template()
            if cfg is None:
                return msg, ""
            return msg, cfg.get("binary_data_dir", "").replace("/binary", "")[5:]
    blk.load(on_load, outputs=[load_st, model_name])

    return blk

# ---------- å…¨å±€è·¯å¾„ ----------
WORKSPACE = Path("/workspace/")
SOFA_BASE = WORKSPACE / "SOFA"
SOME_BASE = WORKSPACE / "SOME"
MDS_BASE  = WORKSPACE / "MakeDiffSinger"

# ---------- äº‹ä»¶ ----------
def set_workspace(path: str):
    global WORKSPACE, SOFA_BASE, SOME_BASE, MDS_BASE
    p = Path(path)
    if not p.is_dir():
        return "  ç›®å½•ä¸å­˜åœ¨"
    WORKSPACE = p
    SOFA_BASE = WORKSPACE / "SOFA"
    SOME_BASE = WORKSPACE / "SOME"
    MDS_BASE  = WORKSPACE / "MakeDiffSinger"
    return f" å·¥ä½œç›®å½•å·²è®¾ä¸ºï¼š{WORKSPACE}"

# SOFA
def sofa_align(model: str, dictionary: str, fmt: str, save_conf: bool):
    if not (model and dictionary):
        return "  æ¨¡å‹/è¯å…¸è·¯å¾„ä¸ºç©º"
    cmd = f'cd "{SOFA_BASE}" && python infer.py --ckpt "{model}" --dictionary "{dictionary}" --out_formats {fmt}'
    if save_conf:
        cmd += " --save_confidence"
    return run_cmd(cmd)

# SOME
def some_extract(model: str, dataset: str, overwrite: bool, enh: bool):
    if not (model and dataset):
        return "  æ¨¡å‹/æ•°æ®é›†è·¯å¾„ä¸ºç©º"
    cmd = f'cd "{SOME_BASE}" && python batch_infer.py --model "{model}" --dataset "{dataset}"'
    if overwrite:
        cmd += " --overwrite"
    if enh:
        cmd += " --use_rmvpe"
    return run_cmd(cmd, timeout=1200)

# MDS
def run_labels_with_img(audio_dir: str, dict_path: str):
    if not (audio_dir and dict_path):
        return "  è·¯å¾„ä¸ºç©º", None
    p = Path(audio_dir)
    if not p.is_dir():
        return f"  å¿…é¡»ä¼ å…¥ç›®å½•ï¼š{audio_dir}", None
    log = run_cmd(
        f'cd "{MDS_BASE}/acoustic_forced_alignment" && python validate_labels.py --dir "{audio_dir}" --dictionary "{dict_path}"',
        60
    )
    img_path = p / "phoneme_distribution.jpg"
    return log, (str(img_path) if img_path.exists() else None)

def run_pitch_with_img(wav_dir: str, tg_dir: str):
    if not (wav_dir and tg_dir):
        return " è·¯å¾„ä¸ºç©º", None
    pw, pt = Path(wav_dir), Path(tg_dir)
    if not (pw.is_dir() and pt.is_dir()):
        return " ä¸¤ä¸ªå‚æ•°éƒ½å¿…é¡»æ˜¯ç›®å½•", None
    log = run_cmd(
        f'cd "{MDS_BASE}/acoustic_forced_alignment" && python summary_pitch.py --wavs "{wav_dir}" --tg "{tg_dir}"',
        120
    )
    img_path = pw / "pitch_distribution.jpg"
    return log, (str(img_path) if img_path.exists() else None)


# ---------- Gradio ----------
with gr.Blocks(title="DiffSinger WEBUIè¯•éªŒç‰ˆ") as demo:
    gr.Markdown("#  DiffSinger WEBUIè¯•éªŒç‰ˆ")

    with gr.Tab(" å·¥ä½œç›®å½•"):
        ws_inp = gr.Textbox(value=str(WORKSPACE), label="å·¥ä½œç›®å½•", lines=1)
        ws_btn = gr.Button("åº”ç”¨", variant="primary")
        ws_state = gr.Textbox(value="å°±ç»ª", label="çŠ¶æ€", interactive=False)
        ws_btn.click(set_workspace, inputs=ws_inp, outputs=ws_state)

    with gr.Tab(" SOFA "):
        mdl = gr.Textbox(label="æ¨¡å‹.ckpt ç»å¯¹è·¯å¾„", placeholder="/SOFA/ckpt/xxx.ckpt")
        dic = gr.Textbox(label="è¯å…¸.txt ç»å¯¹è·¯å¾„", placeholder="/SOFA/dictionary/xxx.txt")
        fmt = gr.Radio(["textgrid", "lab"], value="textgrid", label="è¾“å‡ºæ ¼å¼")
        conf = gr.Checkbox(value=True, label="ä¿å­˜ç½®ä¿¡åº¦")
        btn = gr.Button("å¼€å§‹å¯¹é½", variant="primary")
        log = gr.Textbox(label="è¾“å‡º", lines=10, interactive=False)
        btn.click(sofa_align, inputs=[mdl, dic, fmt, conf], outputs=log)

    with gr.Tab(" SOME "):
        mdl = gr.Textbox(label="æ¨¡å‹.ckpt ç»å¯¹è·¯å¾„", placeholder="/SOME/pretrained/xxx.ckpt")
        dst = gr.Textbox(label="æ•°æ®é›†ç›®å½•ï¼ˆå«wavï¼‰", placeholder="/dataset")
        ow = gr.Checkbox(value=True, label="è¦†ç›–å·²æœ‰")
        enh = gr.Checkbox(value=False, label="RMVPE å¢å¼º")
        btn = gr.Button("å¼€å§‹æå–", variant="primary")
        log = gr.Textbox(label="è¾“å‡º", lines=10, interactive=False)
        btn.click(some_extract, inputs=[mdl, dst, ow, enh], outputs=log)

                        # ===== 4. è®­ç»ƒ =====
    with gr.TabItem("è®­ç»ƒ"):
        build_train_tab() 




    with gr.Tab(" MakeDiffSinger"):
        gr.Markdown("#### 1. æ ¡éªŒéŸ³é¢‘é•¿åº¦")
        d1 = gr.Textbox(placeholder="/segments")
        b1 = gr.Button("è¿è¡Œ")
        o1 = gr.Textbox(lines=4, interactive=False)
        b1.click(lambda x: find_and_run_script("validate_lengths.py", MDS_BASE, f'--dir "{x}"', 30) if x else "   è·¯å¾„ä¸ºç©º", inputs=d1, outputs=o1)
        # --- 2. æ ¡éªŒæ ‡ç­¾+å­—å…¸ ---
        with gr.Group():
            gr.Markdown("### 2. validate_labels.py")
            with gr.Row():
                lab_dir = gr.Textbox(label="éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå«wav+labï¼‰", placeholder="/segments")
                lab_dict = gr.Textbox(label="dictionary.txt ç»å¯¹è·¯å¾„", placeholder="/dictionary.txt")
            lab_btn = gr.Button("è¿è¡Œ", variant="primary")
            lab_out = gr.Textbox(label="è¾“å‡ºæ—¥å¿—", interactive=False, lines=6)
            # 
            lab_img = gr.Image(label="phoneme_distribution.jpg", type="filepath", interactive=False)
            lab_btn.click(run_labels_with_img, inputs=[lab_dir, lab_dict], outputs=[lab_out, lab_img])

        # --- 3. éŸ³é«˜ç»Ÿè®¡ ---
        with gr.Group():
            gr.Markdown("### 3. summary_pitch.py")
            with gr.Row():
                seg_wav = gr.Textbox(label="éŸ³é¢‘æ–‡ä»¶å¤¹è·¯å¾„", placeholder="/segments")
                seg_tg  = gr.Textbox(label="TextGridæ–‡ä»¶å¤¹è·¯å¾„", placeholder="/textgrids")
            sum_btn = gr.Button("è¿è¡Œ", variant="primary")
            sum_out = gr.Textbox(label="è¾“å‡ºæ—¥å¿—", interactive=False, lines=6)
            # 
            sum_img = gr.Image(label="pitch_distribution.jpg", type="filepath", interactive=False)
            sum_btn.click(run_pitch_with_img, inputs=[seg_wav, seg_tg], outputs=[sum_out, sum_img])

        gr.Markdown("#### 4. æ„å»ºè®­ç»ƒé›†")
        d4a = gr.Textbox(placeholder="/segments")
        d4b = gr.Textbox(placeholder="/textgrids")
        d4c = gr.Textbox(placeholder="/xxx/raw")
        b4 = gr.Button("è¿è¡Œ", variant="primary")
        o4 = gr.Textbox(lines=6, interactive=False)
        b4.click(lambda a, b, c: mds_script("/workspace/MakeDiffSinger/acoustic_forced_alignment/build_dataset.py", f'--wavs "{a}" --tg "{b}" --dataset "{c}"', 300) if all([a, b, c]) else "  è·¯å¾„ä¸ºç©º", inputs=[d4a, d4b, d4c], outputs=o4)

        # ===================== 5. äºŒåˆ†å¼å­—å…¸ =====================
        gr.Markdown("#### 5. äºŒåˆ†å¼å­—å…¸ï¼ˆæ±‰è¯­/æ—¥è¯­ç­‰ï¼‰")
        csv_5 = gr.Textbox(label="1. transcriptions.csv ç»å¯¹è·¯å¾„", placeholder="/xxx/raw/transcriptions.csv")
        dict_5 = gr.Textbox(label="2. dictionary.txt ç»å¯¹è·¯å¾„", placeholder="/dictionary.txt")
        btn_5 = gr.Button("è¿è¡Œï¼ˆäºŒåˆ†å¼ï¼‰", variant="primary")
        out_5 = gr.Textbox(lines=6, interactive=False)
        btn_5.click(lambda c, d: run_cmd(
            f'cd "{MDS_BASE}/variance-temp-solution" && python add_ph_num.py "{c}" --dictionary "{d}"', 180) if c and d else "  è·¯å¾„ä¸ºç©º",
            inputs=[csv_5, dict_5], outputs=out_5)
        # ===================== 6. å•éŸ³èŠ‚éŸ³ç´ ç³»ç»Ÿ =====================
        gr.Markdown("#### 6. å•éŸ³èŠ‚éŸ³ç´ ç³»ç»Ÿï¼ˆç²¤è¯­/éŸ©è¯­ç­‰ï¼‰")
        gr.Markdown("**æ­¥éª¤**ï¼šâ‘  å°†æ‰€æœ‰å…ƒéŸ³å†™å…¥ vowels.txtï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ï¼›â‘¡ å°†æ‰€æœ‰è¾…éŸ³å†™å…¥ consonants.txtï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ï¼›â‘¢ è¿è¡Œä¸‹æ–¹å‘½ä»¤")
        csv_6 = gr.Textbox(label="1. transcriptions.csv ç»å¯¹è·¯å¾„", placeholder="/xxx/raw/transcriptions.csv")
        vow_6 = gr.Textbox(label="2. vowels.txt ç»å¯¹è·¯å¾„", placeholder="/vowels.txt")
        con_6 = gr.Textbox(label="3. consonants.txt ç»å¯¹è·¯å¾„", placeholder="/consonants.txt")
        btn_6 = gr.Button("è¿è¡Œï¼ˆå•éŸ³èŠ‚ï¼‰", variant="primary")
        btn_6.click(lambda c, v, co: run_cmd(
            f'cd "{MDS_BASE}/variance-temp-solution" && python add_ph_num.py "{c}" --vowels "{v}" --consonants "{co}"', 180) if all([c, v, co]) else "  è·¯å¾„ä¸ºç©º",
            inputs=[csv_6, vow_6, con_6], outputs=out_5)
        # ===================== 7. å¤šéŸ³èŠ‚éŸ³ç´ ç³»ç»Ÿ =====================
        gr.Markdown("#### 7. å¤šéŸ³èŠ‚éŸ³ç´ ç³»ç»Ÿï¼ˆè‹±è¯­/ä¿„è¯­ç­‰ï¼‰")
        gr.Markdown("**æ­¥éª¤**ï¼šâ‘  å°†æ‰€æœ‰å…ƒéŸ³å†™å…¥ vowels.txtï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ï¼›â‘¡ å°†æ‰€æœ‰è¾…éŸ³å†™å…¥ consonants.txtï¼ˆç©ºæ ¼åˆ†éš”ï¼‰ï¼›â‘¢ å°†æ‰€æœ‰æµéŸ³å†™å…¥ liquids.txtï¼ˆç©ºæ ¼åˆ†éš”ï¼Œå¯æ— ï¼‰ï¼›â‘£ è¿è¡Œä¸‹æ–¹å‘½ä»¤")
        csv_7 = gr.Textbox(label="1. transcriptions.csv ç»å¯¹è·¯å¾„", placeholder="/xxx/raw/transcriptions.csv")
        tg_7  = gr.Textbox(label="2. TextGrid æ–‡ä»¶å¤¹ç»å¯¹è·¯å¾„", placeholder="/xxx/raw/textgrids")
        vow_7 = gr.Textbox(label="3. vowels.txt ç»å¯¹è·¯å¾„", placeholder="/vowels.txt")
        con_7 = gr.Textbox(label="4. consonants.txt ç»å¯¹è·¯å¾„", placeholder="/consonants.txt")
        liq_7 = gr.Textbox(label="5. liquids.txt ç»å¯¹è·¯å¾„ï¼ˆå¯ç©ºï¼‰", placeholder="/liquids.txt")
        btn_7 = gr.Button("è¿è¡Œï¼ˆå¤šéŸ³èŠ‚ï¼‰", variant="primary")
        btn_7.click(lambda c, tg, v, co, l: run_cmd(
            f'cd "{MDS_BASE}/variance-temp-solution" && python add_ph_num_advanced.py "{c}" --tg "{tg}" --vowels "{v}" --consonants "{co}"' + (f' --liquids "{l}"' if l else ""), 180) if all([c, tg, v, co]) else "  è·¯å¾„ä¸ºç©º",
            inputs=[csv_7, tg_7, vow_7, con_7, liq_7], outputs=out_5)
                        # ===== 5. ONNX å¯¼å‡º =====
    with gr.TabItem("ONNX å¯¼å‡º"):
        build_onnx_tab()
    






    
    
    with gr.Tab("é…ç½®æ–‡ä»¶"):
        with gr.Tabs():
            # ===== 1. å£°å­¦é…ç½® =====
            with gr.TabItem("å£°å­¦é…ç½®ï¼ˆåªèƒ½çœ‹çœ‹ï¼Œå®é™…ä¸Šæ— æ³•ä½¿ç”¨ï¼‰"):
                build_acoustic_subtab()     
            # ===== 2. å”±æ³•é…ç½® =====
            with gr.TabItem("å”±æ³•é…ç½®ï¼ˆåªèƒ½çœ‹çœ‹ï¼Œå®é™…ä¸Šæ— æ³•ä½¿ç”¨ï¼‰"):
                build_variance_subtab()
            # ===== 3. æ–‡æœ¬ç¼–è¾‘å™¨ =====
            with gr.TabItem("é…ç½®æ–‡æœ¬ç¼–è¾‘å™¨"):
                build_mini_editor()






demo.launch(
    server_name="0.0.0.0", 
    server_port=7861, 
    share=True,
    allowed_paths=["/"]
)